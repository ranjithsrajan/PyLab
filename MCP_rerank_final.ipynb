{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjithsrajan/PyLab/blob/main/MCP_rerank_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Engineering for your MCP Client\n",
        "## Dynamic MCP Selection: Using Contextual’s Reranker to Pick the Right Tools for Your Task\n",
        "##### Written by: Qile Jiang\n",
        "##### Last updated on: 7.31.25\n",
        "##### Reference blog: https://contextual.ai/blog/context-engineering-for-your-mcp-client\n",
        "\n",
        "Thousands of MCP servers exist and many are updated daily, making server selection difficult for LLMs.\n",
        "- Current approaches require manually downloading and configuring servers, limiting flexibility.\n",
        "- When multiple servers are pre-configured, LLMs get overwhelmed and confused about which server to use for specific tasks.\n",
        "\n",
        "This workflow enables dynamic server selection from a live [PulseMCP](http://pulsemcp.com) directory of 5000+ servers.\n",
        "- A user query goes to an LLM that decides whether to use MCP servers, then the LLM generates instructions for ranking relevant servers.\n",
        "- [Contextual AI](https://contextual.ai)'s [reranker](https://contextual.ai/blog/introducing-instruction-following-reranker/) prioritizes servers based on these instructions, allowing real-time server discovery rather than being limited to manually downloaded servers."
      ],
      "metadata": {
        "id": "W0bAqSaDJTBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install requests openai openai mcp-use python-dotenv contextual-client -q"
      ],
      "metadata": {
        "id": "XD-9HNVT7o4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1090596-3e64-48c4-d0ef-b5e584928a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.8/175.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import asyncio\n",
        "import json\n",
        "import tempfile\n",
        "import os\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from mcp_use import MCPAgent, MCPClient\n",
        "from contextual import ContextualAI"
      ],
      "metadata": {
        "id": "mHO10ObUJzK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step (1) We'll start by setting up our API connections to OpenAI for LLM queries and Contextual AI for reranking.\n",
        "\n",
        "Sign up for a free trial of Contextual [here](https://app.contextual.ai/) to find `CONTEXTUAL_API_KEY`\n",
        "\n",
        "For the reranker prompt generator and baseline model, we have used OpenAI's `GPT-4o-mini`, you can find your OpenAI API key [here](https://platform.openai.com/api-keys) or swap this section out to use the LLM of your choice."
      ],
      "metadata": {
        "id": "lqX5XFgmrjeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API keys from Google Colab secrets\n",
        "contextual_api_key = userdata.get(\"CONTEXTUAL_API_KEY\")\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "# Initialize clients\n",
        "llm_client = OpenAI(api_key=openai_api_key)\n",
        "contextual_client = ContextualAI(api_key=contextual_api_key, base_url=\"https://api.contextual.ai/v1\")"
      ],
      "metadata": {
        "id": "KyE8Z4_0LG0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step (2) Next, we fetch all available MCP servers from the Pulse MCP API and format them as documents for reranking."
      ],
      "metadata": {
        "id": "wkTJn5YyrmZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch all MCP servers from Pulse MCP API\n",
        "servers = []\n",
        "offset = 0\n",
        "\n",
        "while True:\n",
        "    response = requests.get(\n",
        "        \"https://api.pulsemcp.com/v0beta/servers\",\n",
        "        params={\"count_per_page\": 5000, \"offset\": offset},\n",
        "        headers={\"User-Agent\": \"MCPCollector/1.0\"}\n",
        "    )\n",
        "\n",
        "    data = response.json()\n",
        "    batch = data[\"servers\"]\n",
        "\n",
        "    servers.extend(batch)\n",
        "\n",
        "    if not data.get(\"next\"):\n",
        "        break\n",
        "\n",
        "    offset += 5000\n",
        "\n",
        "mcp_servers = [{\n",
        "    \"name\": server[\"name\"],\n",
        "    \"short_description\": server[\"short_description\"],\n",
        "    \"github_stars\": server[\"github_stars\"],\n",
        "    \"package_download_count\": server[\"package_download_count\"],\n",
        "    \"EXPERIMENTAL_ai_generated_description\": server[\"EXPERIMENTAL_ai_generated_description\"],\n",
        "    \"source_code_url\": server.get(\"source_code_url\"),\n",
        "    \"package_registry\": server.get(\"package_registry\"),\n",
        "    \"package_name\": server.get(\"package_name\"),\n",
        "    \"remotes\": server.get(\"remotes\", [])\n",
        "} for server in servers]\n",
        "\n",
        "print(f\"Loaded {len(mcp_servers)} MCP servers\")\n",
        "\n",
        "# Prepare documents and metadata for reranking\n",
        "documents = []\n",
        "metadata = []\n",
        "\n",
        "for server in mcp_servers:\n",
        "    doc_parts = [\n",
        "        f\"MCP Server: {server['name']}\",\n",
        "        f\"Description: {server['short_description']}\",\n",
        "    ]\n",
        "\n",
        "    # # This would be nice but adding the ai generated description will exceed token count\n",
        "    # if server['EXPERIMENTAL_ai_generated_description']:\n",
        "    #     doc_parts.append(f\"AI Description: {server['EXPERIMENTAL_ai_generated_description']}\")\n",
        "\n",
        "    documents.append(\"\\n\".join(doc_parts))\n",
        "    metadata.append(f\"Name: {server['name']}, Stars: {server['github_stars']}, Downloads: {server['package_download_count']}, Downloads: {server['remotes']}\")\n",
        "\n",
        "print(f\"Prepared {len(documents)} documents for reranking\")\n",
        "print(f\"\\nExample: {documents[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckIxdWmtLIVr",
        "outputId": "998712cf-41a9-4aa4-ccd7-9992665409fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5512 MCP servers\n",
            "Prepared 5512 documents for reranking\n",
            "\n",
            "Example: MCP Server: Laravel DebugBar\n",
            "Description: Provides a bridge to Laravel DebugBar for accessing detailed request logs, queries, routes, views, and models with filtering capabilities and formatted output for improved readability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step (3) Now we test our workflow with a sample query, asking the LLM to determine whether MCP servers are needed."
      ],
      "metadata": {
        "id": "6H-OfJAIrsot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_mcp(query):\n",
        "    \"\"\"Analyze query, Generate reranking instruction if MCP server is needed.\"\"\"\n",
        "\n",
        "    prompt_reranker = f\"\"\"\n",
        "        Analyze this user query and decide if it requires external tools/APIs (Model Context Protocol (MCP) servers) or can be answered directly.\n",
        "        Query: \"{query}\"\n",
        "\n",
        "        Consider:\n",
        "        - Does it need real-time data, web search, or external APIs?\n",
        "        - Does it require specialized tools (file management, databases, etc.)?\n",
        "        - Is it a complex task that would benefit from external services?\n",
        "        - Can it be answered with general knowledge alone?\n",
        "\n",
        "        If MCP is needed, also generate a concise reranking instruction for selecting the best external tools/APIs (MCPs) for this query.\n",
        "\n",
        "        The instruction should:\n",
        "        - Specify the exact capabilities/features/details that an MCP server requires for this query\n",
        "        - Look for domain/field specificity and functionality needs\n",
        "        - Any specific requirements that the user asks for\n",
        "        - Highlight the user's prioritized criteria for server selection\n",
        "\n",
        "        Base the instruction only on what is explicitly stated or clearly implied in the user's query.\n",
        "        Do not assume additional requirements or preferences that are not present in the query.\n",
        "\n",
        "        Respond with JSON: {{\"use_mcp\": true/false, \"reason\": \"brief explanation\", \"instruction\": \"reranking instruction text or null if not needed\"}}\n",
        "        \"\"\"\n",
        "\n",
        "    response = llm_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_reranker}],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return json.loads(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "pX4zDLebMvOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Find most recent information about CRISPR gene editing applications in treating sickle cell disease. I need trustworthy sources.\"\n",
        "# query = \"What is the capital of France?\"\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "decision = decide_mcp(query)\n",
        "print(f\"\\nUse MCP: {decision['use_mcp']} - {decision['reason']}\")\n",
        "if decision['use_mcp']:\n",
        "    print(f\"\\nReranking Instruction: {decision['instruction']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1UpwyL44wbk",
        "outputId": "1ab0e078-47c5-4577-c336-7382014d4c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Find most recent information about CRISPR gene editing applications in treating sickle cell disease. I need trustworthy sources.\n",
            "\n",
            "Use MCP: True - The query requires the most recent information, which suggests a need for real-time data and trustworthy sources that may not be available in the model's training data.\n",
            "\n",
            "Reranking Instruction: Select MCP servers that provide access to recent scientific publications, news articles, and databases specifically focused on gene editing technologies and medical applications. Ensure the sources are reputable and peer-reviewed, with a focus on CRISPR applications in sickle cell disease.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step (4) We use the Contextual AI reranker to score and rank all MCP servers based on our query and instructions."
      ],
      "metadata": {
        "id": "6MGjgN1-r8y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_servers(query, instruction, documents, metadata, mcp_servers):\n",
        "    \"\"\"Rerank MCP servers based on query and instruction, display results.\"\"\"\n",
        "\n",
        "    rerank_response = contextual_client.rerank.create(\n",
        "        query=query,\n",
        "        instruction=instruction,\n",
        "        documents=documents,\n",
        "        metadata=metadata,\n",
        "        model=\"ctxl-rerank-en-v1-instruct\"\n",
        "    )\n",
        "\n",
        "    print(\"Reranking Results:\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"\\nReranking Instruction: {instruction}\")\n",
        "    print(f\"Top 5 recommended MCP servers:\")\n",
        "    for i, result in enumerate(rerank_response.results[:5]):\n",
        "        print(f\"\\n{i+1}. Score: {result.relevance_score:.4f}\")\n",
        "        print(f\" Server: {mcp_servers[result.index]['name']}\")\n",
        "        print(f\" Stars: {mcp_servers[result.index]['github_stars']}\")\n",
        "        print(f\" Downloads: {mcp_servers[result.index]['package_download_count']}\")\n",
        "        print(f\" Description: {mcp_servers[result.index]['short_description']}\")\n",
        "        print(f\" Remote: {mcp_servers[result.index]['remotes']}\")\n",
        "\n",
        "    return rerank_response.results[0].index, rerank_response.results[0].relevance_score"
      ],
      "metadata": {
        "id": "ztWATzm941LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select best MCP server using reranker\n",
        "if decision['use_mcp']:\n",
        "    best_server_index, relevance_score = rerank_servers(query, decision['instruction'], documents, metadata, mcp_servers)\n",
        "    selected_server = mcp_servers[best_server_index]\n",
        "else:\n",
        "    print(\"No server is needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aMaGnShMvKb",
        "outputId": "0304c50e-184e-4d5b-f8fe-a7d8ee4d913d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reranking Results:\n",
            "Query: Find most recent information about CRISPR gene editing applications in treating sickle cell disease. I need trustworthy sources.\n",
            "\n",
            "Reranking Instruction: Select MCP servers that provide access to recent scientific publications, news articles, and databases specifically focused on gene editing technologies and medical applications. Ensure the sources are reputable and peer-reviewed, with a focus on CRISPR applications in sickle cell disease.\n",
            "Top 5 recommended MCP servers:\n",
            "\n",
            "1. Score: 0.6540\n",
            " Server: Gemini with Web Search\n",
            " Stars: 4\n",
            " Downloads: None\n",
            " Description: Integrates Google's Gemini model with real-time web search and YouTube data to enhance AI responses with up-to-date information from the internet.\n",
            " Remote: []\n",
            "\n",
            "2. Score: 0.6301\n",
            " Server: PubMed Medical Literature Research\n",
            " Stars: 1\n",
            " Downloads: None\n",
            " Description: Enables search, retrieval, and analysis of academic medical literature through the NCBI PubMed database with formatted citations and researcher publication statistics.\n",
            " Remote: []\n",
            "\n",
            "3. Score: 0.6240\n",
            " Server: Scientific Paper Analyzer (Gemini)\n",
            " Stars: 3\n",
            " Downloads: None\n",
            " Description: Integrates with Google's Gemini API to enable searching, analyzing and exploring academic research papers with tools for citation graphs and detailed paper information retrieval\n",
            " Remote: []\n",
            "\n",
            "4. Score: 0.6178\n",
            " Server: Perplexity Deep Research\n",
            " Stars: 6\n",
            " Downloads: None\n",
            " Description: Integrates with Perplexity's sonar-deep-research model to enable web searches with citation support and optional recency filtering for up-to-date information retrieval.\n",
            " Remote: []\n",
            "\n",
            "5. Score: 0.6178\n",
            " Server: Research Orchestration\n",
            " Stars: 5\n",
            " Downloads: None\n",
            " Description: Orchestrates intelligent research workflows by selecting and executing specialized tools (Brave Search, Tavily, GitHub, arXiv, news APIs) based on query context, synthesizing results into well-cited answers with iterative refinement and source attribution.\n",
            " Remote: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison to baseline"
      ],
      "metadata": {
        "id": "My_adJ09UcGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate documents to fit within OpenAI context length\n",
        "max_tokens = 128000 - 2000\n",
        "max_chars = (max_tokens // len(documents)) * 4\n",
        "docs_GPT = [doc[:max_chars] for doc in documents]"
      ],
      "metadata": {
        "id": "AHUG97fj483X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_approach(q, docs_GPT):\n",
        "    \"\"\"Get baseline MCP server recommendations using simple LLM prompt.\"\"\"\n",
        "\n",
        "    prompt_baseline = f\"\"\"\n",
        "        You are given a user query and a list of MCP servers. Query: {q} MCP Servers: {docs_GPT}.\n",
        "\n",
        "        Return the top 5 most relevant MCP server from the list to answer this query.\n",
        "        Provide their server names.\n",
        "\n",
        "        If no MCP server is relevant or needed, respond with \"None\".\n",
        "        \"\"\"\n",
        "\n",
        "    response_baseline = llm_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_baseline.replace(\"{query}\", q)}],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response_baseline.choices[0].message.content"
      ],
      "metadata": {
        "id": "Rt8zP2MCqtx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    # \"Help me manage GitHub repositories with automated testing and CI/CD workflows.\",\n",
        "    # \"Help me automate my g-mail responses while I'm out of office.\",\n",
        "    # \"Retrieve latest NBA game scores with official league statistics.\",\n",
        "    # \"Get real-time trading info for APPL. Do some AI-driven financial analysis on it.\",\n",
        "    # \"Show trending opinions and discussions about climate change. Only consider non-US platforms.\",\n",
        "    # \"I have many complex enterprise documents. I want to build an agent that lets me interact with and query these docs through natural conversation.\"\n",
        "    \"I want to send an email or a text or call someone via MCP, and I want the server to be remote and have high user rating\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(f\"\\n--- Query: {q} ---\")\n",
        "    ##################### Reranker approach #####################\n",
        "    decision = decide_mcp(q)\n",
        "    print(f\"\\nUse MCP: {decision['use_mcp']} - {decision['reason']}\")\n",
        "    if decision['use_mcp']:\n",
        "        print(f\"\\nReranking Instruction: {decision['instruction']}\")\n",
        "        rerank_servers(q, decision['instruction'], documents, metadata, mcp_servers)\n",
        "\n",
        "    ##################### Baseline approach #####################\n",
        "    print(\"\\nBaseline top 5 MCP servers:\")\n",
        "    print(baseline_approach(q, docs_GPT))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHbo0i7Q4_SA",
        "outputId": "f3e48191-4e5d-4497-cd42-8617d27437a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Query: I want to send an email or a text or call someone via MCP, and I want the server to be remote and have high user rating ---\n",
            "\n",
            "Use MCP: True - The user is looking for a remote server with high user ratings to send an email, text, or make a call, which requires real-time data and external APIs.\n",
            "\n",
            "Reranking Instruction: Select MCP servers that offer capabilities for sending emails, texts, and making calls. Ensure the servers are remote and have high user ratings. Prioritize those with a user-friendly interface and reliable performance in communication services.\n",
            "Reranking Results:\n",
            "Query: I want to send an email or a text or call someone via MCP, and I want the server to be remote and have high user rating\n",
            "\n",
            "Reranking Instruction: Select MCP servers that offer capabilities for sending emails, texts, and making calls. Ensure the servers are remote and have high user ratings. Prioritize those with a user-friendly interface and reliable performance in communication services.\n",
            "Top 5 recommended MCP servers:\n",
            "\n",
            "1. Score: 0.9081\n",
            " Server: Activepieces\n",
            " Stars: 16275\n",
            " Downloads: 1789\n",
            " Description: Dynamic server to which you can add apps (Google Calendar, Notion, etc) or advanced Activepieces Flows (Refund logic, a research and enrichment logic, etc).\n",
            " Remote: [{'url_direct': None, 'url_setup': 'https://www.activepieces.com/docs/ai/mcp', 'transport': 'sse', 'authentication_method': 'oauth', 'cost': 'free_tier'}]\n",
            "\n",
            "2. Score: 0.8915\n",
            " Server: ilert\n",
            " Stars: 13\n",
            " Downloads: None\n",
            " Description: Integrates with ilert's alerting and incident management platform to provide direct access to alerting workflows, incident data, and on-call management through a remote HTTP transport requiring only API key authentication.\n",
            " Remote: [{'url_direct': 'https://mcp.ilert.com/mcp', 'url_setup': 'https://www.docs.ilert.com/developer-docs/mcp', 'transport': 'streamable_http', 'authentication_method': None, 'cost': None}]\n",
            "\n",
            "3. Score: 0.8902\n",
            " Server: Zapier\n",
            " Stars: None\n",
            " Downloads: None\n",
            " Description: Generate a dynamic MCP server that connects to any of your favorite 8000+ apps on Zapier.\n",
            " Remote: [{'url_direct': None, 'url_setup': 'https://zapier.com/mcp', 'transport': 'sse', 'authentication_method': 'oauth', 'cost': 'free_tier'}]\n",
            "\n",
            "4. Score: 0.8650\n",
            " Server: Vapi\n",
            " Stars: 25\n",
            " Downloads: 3049\n",
            " Description: Integrates with Vapi's AI voice calling platform to manage voice assistants, phone numbers, and outbound calls with scheduling support through eight core tools for automating voice workflows and building conversational agents.\n",
            " Remote: [{'url_direct': 'https://mcp.vapi.ai/mcp', 'url_setup': None, 'transport': 'streamable_http', 'authentication_method': 'api_key', 'cost': 'paid'}, {'url_direct': 'https://mcp.vapi.ai/sse', 'url_setup': None, 'transport': 'sse', 'authentication_method': 'api_key', 'cost': 'paid'}]\n",
            "\n",
            "5. Score: 0.8372\n",
            " Server: Tavily Search\n",
            " Stars: 663\n",
            " Downloads: 141705\n",
            " Description: Integrates with Tavily API to provide real-time web search and content extraction capabilities for research, aggregation, and fact-checking tasks.\n",
            " Remote: [{'url_direct': 'https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key> ', 'url_setup': None, 'transport': 'streamable_http', 'authentication_method': 'api_key', 'cost': 'free_tier'}]\n",
            "\n",
            "Baseline top 5 MCP servers:\n",
            "Based on your query about sending an email, text, or making a call via a remote MCP server with a high user rating, the following MCP servers are relevant:\n",
            "\n",
            "1. **Email Server**\n",
            "2. **Gmail**\n",
            "3. **Twilio Messaging**\n",
            "4. **Telegram**\n",
            "5. **Protonmail**\n",
            "\n",
            "These servers can facilitate email and messaging functionalities as per your request.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Easy queries:\n",
        "\n",
        "For queries that are straightforward, both the reranker and baseline LLM give similar results.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 1: Help me manage GitHub repositories with automated testing and CI/CD workflows.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **GitHub**¹ | GitHub |\n",
        "| 2 | **GitHub**² | GitHub Actions |\n",
        "| 3 | **GitHub (via OAuth)**³ | GitHub PR Helper |\n",
        "| 4 | **GitHub**⁴ | GitHub Projects |\n",
        "| 5 | **GitHub**⁵ | GitHub Repository Browser |\n",
        "\n",
        "¹ Integrates with GitHub's API to enable repository management, file operations, issue tracking, pull request handling, and workflow automation with configurable security controls for development workflows.  \n",
        "² Integrates with GitHub's API to enable repository management, code manipulation, and issue tracking for streamlined development workflows.  \n",
        "³ Integrates with GitHub's OAuth system to enable secure access and management of repositories, issues, and code for automated development workflows and analysis.  \n",
        "⁴ Integrates with GitHub using Octokit to enable repository management, issue tracking, and code analysis.  \n",
        "⁵ Integrates with GitHub's API to enable repository management, code manipulation, issue tracking, and pull request handling for streamlined development workflows.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 2: Help me automate my g-mail responses while I'm out of office.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **Gmail**¹ | Gmail |\n",
        "| 2 | **Gmail**² | Google Workspace |\n",
        "| 3 | **Google Workspace Automation**³ | Email Sender |\n",
        "| 4 | **Gmail**⁴ | Outlook Email Processor |\n",
        "| 5 | **Gmail**⁵ | Resend Email |\n",
        "\n",
        "¹ Integrates with Gmail's API to enable email operations including sending, receiving, and managing emails for automation and workflow integration.  \n",
        "² Integrates with Gmail APIs to enable reading, sending, and managing emails across multiple accounts, supporting automated email processing and workflow integration.  \n",
        "³ Integrates with Google Workspace services through Google Apps Script Web Apps to automate Gmail, Calendar, Drive, Docs, Sheets, Slides, and Forms operations including email management, event scheduling, file handling, document creation, and form building with weather data retrieval and presentation generation capabilities.  \n",
        "⁴ Integrates with Gmail's API to enable email management tasks like sending, reading, drafting, and organizing messages.  \n",
        "⁵ Integrates with Gmail to enable natural language-based email management, including searching, reading, deleting, and sending emails with attachment support and conversation threading.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 3: Retrieve latest NBA game scores with official league statistics.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **NBA Stats**¹ | MCP Server: NBA Stats |\n",
        "| 2 | **Web Search (Brave)**² | MCP Server: NBA Player Stats |\n",
        "| 3 | **NBA Stats**³ | MCP Server: NBA Stats |\n",
        "| 4 | **MCP Advisor**⁴ | MCP Server: NBA Player Stats |\n",
        "| 5 | **WebMCP**⁵ | MCP Server: NBA Stats |\n",
        "\n",
        "¹ Provides real-time NBA game data including scores, player statistics, and play-by-play information through the nba_api package for accessing current basketball information not in Claude's training data.  \n",
        "² Integrates Brave Search API for real-time web information retrieval, dynamically categorizing queries to proactively fetch current events, weather, sports scores, and time-sensitive data with robust error handling.  \n",
        "³ Provides a Python-based interface to NBA statistics and live game data, offering tools for accessing game information, player statistics, team data, and league standings without requiring knowledge of the underlying API structure.  \n",
        "⁴ Discovery and recommendation service that helps find and understand available MCP services based on natural language queries, supporting multiple search backends for exploring servers by semantic similarity.  \n",
        "⁵ Turn any website into an MCP server with customizable tools."
      ],
      "metadata": {
        "id": "6x6gCrldmUto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Queries with specific requirements\n",
        "\n",
        "For more complicated queries with specific requirements from the user, the reranker is able to prioritize the user's preferences.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 1: Get real-time trading info for APPL. Do some AI-driven financial analysis on it.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **XTQuant AI**¹ | Yahoo Finance |\n",
        "| 2 | **Stockflow (Yahoo Finance)**² | AlphaVantage Trader |\n",
        "| 3 | **Yahoo Finance**³ | CoinGecko |\n",
        "| 4 | **Yahoo Finance**⁴ | Stock Market (Alpha Vantage) |\n",
        "| 5 | **Alpha Vantage**⁵ | Zerodha Kite |\n",
        "\n",
        "¹ Lightweight Python server for quantitative trading using XTQuant API, enabling real-time stock market interactions and AI-driven financial analysis strategies.  \n",
        "² Integrates with the Yahoo Finance API to provide real-time stock market data and analysis tools for financial research and trading strategies.  \n",
        "³ Provides real-time financial data and visualization tools through Yahoo Finance API for stock prices, company information, and market analysis with interactive charts and dashboards.  \n",
        "⁴ Provides real-time financial data from Yahoo Finance through specialized tools for retrieving stock information, market trends, and news for investment research and analysis.  \n",
        "⁵ Provides real-time financial data retrieval from Alpha Vantage, enabling developers and analysts to access comprehensive stock prices, market indicators, forex rates, and cryptocurrency information with instant, structured results.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 2: Show trending opinions and discussions about climate change. Only consider non-US platforms.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **Chinese Trends Hub**¹ | ClimateTriage |\n",
        "| 2 | **Hotnews (Chinese Social)**² | Twitter Search |\n",
        "| 3 | **Beyond Social (Farcaster)**³ | Reddit |\n",
        "| 4 | **PulseMCP**⁴ | GNews |\n",
        "| 5 | **X (Twitter)**⁵ | Newsdata |\n",
        "\n",
        "¹ Provides real-time access to trending topics and content from major Chinese platforms including Weibo, Zhihu, Douyin, Bilibili, Douban, Toutiao, and 36kr through separate tools with temporary caching for improved performance.  \n",
        "² Aggregates real-time trending topics from major Chinese social platforms and news sites.  \n",
        "³ Integrates with social platforms like Farcaster to provide standardized access to user profiles, content search, thread analysis, and trending topics through flexible stdio and HTTP/SSE transports.  \n",
        "⁴ Integrates with PulseMCP to enable querying and retrieval of MCP server and integration data for ecosystem analysis and service recommendations.  \n",
        "⁵ Integrates with X's API to enable tweet retrieval, user interactions, and social media analysis capabilities.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Query 3: I need to process large-scale datasets from my PostgreSQL database efficiently. Find an easy way to do it.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **Ollama PostgreSQL Data Analysis**¹ | PostgreSQL |\n",
        "| 2 | **DBHub (Universal Database Gateway)**² | PostgreSQL |\n",
        "| 3 | **PostgreSQL Database Manager**³ | PostgreSQL |\n",
        "| 4 | **Supabase PostgreSQL**⁴ | PostgreSQL |\n",
        "| 5 | **PostgreSQL Database Manager**⁵ | PostgreSQL |\n",
        "\n",
        "¹ Integrates natural language querying with PostgreSQL databases to enable AI-interpreted data analysis without manual SQL writing.  \n",
        "² Provides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks.  \n",
        "³ Integrates with PostgreSQL databases to enable schema management, data migration, performance monitoring, and security configuration through direct database operations without requiring separate management tools.  \n",
        "⁴ Integrates with Supabase PostgreSQL databases, exposing table schemas as resources and providing tools for data analysis, including read-only SQL queries, table statistics, and relationship discovery.  \n",
        "⁵ Integrates with PostgreSQL to provide database analysis, optimization, and troubleshooting tools for streamlined management and performance tuning.\n",
        "\n",
        "---\n",
        "\n",
        "**Query 4: I have many complex enterprise documents. I want to build an agent that lets me interact with and query these docs through natural conversation.**\n",
        "\n",
        "| Rank | Reranker | Baseline |\n",
        "|------|----------|---------|\n",
        "| 1 | **Contextual AI**¹ | Document Operations (Word, Excel, PDF) |\n",
        "| 2 | **Lokka (Microsoft Graph)**² | PDF Reader |\n",
        "| 3 | **DocuMCP (RAG Documentation Server)**³ | Documentation Manager |\n",
        "| 4 | **Glean**⁴ | Markdown to PDF |\n",
        "| 5 | **Kollektiv Document Management**⁵ | Google Docs |\n",
        "\n",
        "¹ Integrates with Contextual AI's platform to provide enterprise search, multi-agent routing with automatic reranking, and intelligent document navigation that leverages hierarchical structure analysis for conversational access to knowledge bases and complex documents.  \n",
        "² Provides a bridge between Microsoft Graph API and natural language interaction, enabling conversational management of Microsoft 365 tenants without complex API calls.  \n",
        "³ RAG-enabled documentation server that integrates with vector databases to provide semantic search capabilities for code, documentation, and diagrams without data leaving your environment.  \n",
        "⁴ Integrates Glean's search and chat APIs to enable natural language interactions with organizational knowledge bases and chatbots.  \n",
        "⁵ Enables AI to search and analyze user-uploaded documents through Kollektiv's document management system with secure OAuth authentication and natural language querying capabilities.\n"
      ],
      "metadata": {
        "id": "qnkLAl-pkxTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost estimate:\n",
        "*   Contextual AI Reranker (with full MCP docs): ~$0.035/query\n",
        "\n",
        "Includes 0.035 for reranking + ~$0.0001 for OpenAI instruction generation\n",
        "\n",
        "*   OpenAI Baseline: ~$0.017/query\n",
        "\n"
      ],
      "metadata": {
        "id": "qNrqxzM8tmEk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnOAxLo0tzWM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}