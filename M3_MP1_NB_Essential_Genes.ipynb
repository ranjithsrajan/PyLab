{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjithsrajan/PyLab/blob/main/M3_MP1_NB_Essential_Genes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powered-thong"
      },
      "source": [
        "# Applied Data Science and Machine Intelligence\n",
        "## A program by IIT Madras and TalentSprint\n",
        "### Mini Project 01: Prediction of Essential Genes from Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nK0fzdQzk0g"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the mini project, you will be able to -\n",
        "\n",
        "* Get an understanding of the dataset.\n",
        "* Build and analyze Networks (or Graphs)\n",
        "* Extract features from the network\n",
        "* Predict Essential Genes using the classification algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xoyNc-yTy7U"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvhRny6xpviu"
      },
      "source": [
        "### Background of the project\n",
        "\n",
        "This Mini-Project is based on the research work based out of Robert Bosch Center for Data Science and Artificial Intelligence (RBCDSAI) at IIT Madras. More details can be found in this article [https://doi.org/10.3389/fgene.2021.722198](https://www.frontiersin.org/articles/10.3389/fgene.2021.722198/full).\n",
        "\n",
        "The goal of this project is to apply machine learning to predict Essential Genes using the Protein network as the features of the STRING dataset.\n",
        "\n",
        "### About the paper cited above\n",
        "\n",
        "Features Used in the Paper\n",
        "\n",
        "267 Genetic Featues + 16 Network Centrality features.\n",
        "\n",
        "12 Centralities [1 to 12] + 4 other Auxillary network metrics\n",
        "\n",
        "These features are computed from the graph. Once extracted, they translate the Omics-Data into a typical machine learning data, which can be further developed with Machine learning Models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFyE8NDOUPyq"
      },
      "source": [
        "### About the Dataset\n",
        "\n",
        "The dataset will be directly downloaded from the [String Database](https://string-db.org/cgi/download) , in a very convenient manner.\n",
        "We are downloading and working on the bacterium *Actinomyces coleocanis* as it is a small dataset suitable for the runtime and quick reruns.\n",
        "[Actinomyces coleocanis](https://stringdb-static.org/download/protein.links.v11.5/525245.protein.links.v11.5.txt.gz) will be downloaded and unzipped. The text file contains 3 columns - protein1, protein2 and score.\n",
        "This 3 column data is a graph data.\n",
        "\n",
        "The Netgenes contains essential gene predictions for 2,700+ bacteria predicted using features derived from STRING protein–protein functional association networks. It contains a re fined version to access and download the data with some information as well. The dataset contains the essential genes for each bacteria.\n",
        "Clicking on the specific bacteria name will navigate to an interactive\n",
        "page.\n",
        "[Netgenes Database](https://rbc-dsai-iitm.github.io/NetGenes/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gn0Nbv1UXGG"
      },
      "source": [
        "### Small note on Proteins\n",
        "\n",
        "Proteins are large, complex molecules that play many critical roles in the body. They are necessary for building the structural components of the human body, such as muscles and organs. Proteins also determine how the organism looks, how well its body metabolises food or fights infection and sometimes even how it behaves. Proteins are chains of chemical building blocks called amino acids. A protein may contain a few amino acids or it could have several thousands.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd3yZ7DNUk-F"
      },
      "source": [
        "\n",
        "### Small note on Genes\n",
        "\n",
        "A gene is a basic unit of heredity in a living organism that normally resides in long strands of DNA called chromosomes. Genes are coded instructions that decide what the organism is like, how it behaves in its environment and how it survives. They hold the information to build and maintain an organism’s cells and pass genetic traits to offspring. A gene consists of a long combination of four different nucleotide bases namely adenine, cytosine, guanine and thymine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqeoDkjTUnbY"
      },
      "source": [
        "### Relationship between GENES and PROTEINS\n",
        "Gene and protein are two functionally-related entities found in the cell of an living organism.\n",
        "Most genes contain the information require to make proteins. Please note Gene is not a part of Protein and vice-versa.\n",
        "For more information, click [Here](https://pediaa.com/difference-between-gene-and-protein/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qmtwn5XUq-O"
      },
      "source": [
        "\n",
        "\n",
        "### Importance of Essential Genes\n",
        "Essential genes are genes required for a cell or an organism to survive. Some of the functinalities are cell growth and metabolism, cell reproduction, its well-being etc. Disruption or deletion of such genes causes cell death, indicating that these genes perform essential biological functions. A majority of the Genes in an organism are NON-ESSENTIAL. Only a small fraction are Essential."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hungry-accident"
      },
      "source": [
        "**Python Packages used:**  \n",
        "* [`networkx`](https://networkx.org/documentation/stable/_downloads/networkx_reference.pdf) for graph analysis\n",
        "* [`requests`](https://docs.python-requests.org/en/latest/) for fetching data over the internet\n",
        "* [`Pandas`](https://pandas.pydata.org/docs/reference/index.html) for data frames and easy to read csv files  \n",
        "* [`Numpy`](https://numpy.org/doc/stable/reference/index.html#reference) for array and matrix mathematics functions  \n",
        "* [`sklearn`](https://scikit-learn.org/stable/user_guide.html) for the metrics and pre-processing\n",
        "* [`seaborn`](https://seaborn.pydata.org/) and [`matplotlib`](https://matplotlib.org/) for plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset\n",
        "%%capture\n",
        "!gdown \"1Is_iOj98tsKG_J2RXxSagc8QLIASBDfk\"\n",
        "!unzip \"Essential genes data.zip\"\n",
        "!pip install networkx==2.4"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hFKowWm0pniH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-g3SLm-DLEW"
      },
      "source": [
        "## Importing the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_V0z4eaDILg"
      },
      "outputs": [],
      "source": [
        "### The required libraries and packages ###\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "from google.colab import drive\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw7Z9BHgU0PL"
      },
      "source": [
        "## Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdduayuwN171"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv('525245.protein.links.v11.5.txt', sep = '\\s',engine = \"python\")\n",
        "print(df_raw.shape)\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbGi8TFG8MWy"
      },
      "outputs": [],
      "source": [
        "df = df_raw.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGgGUca_gSDV"
      },
      "outputs": [],
      "source": [
        "print(f\"df.shape = {df.shape}\")\n",
        "n_uniq_protein1 = df[\"protein1\"].nunique()\n",
        "n_uniq_protein2 = df[\"protein2\"].nunique()\n",
        "print(f\"n_uniq_protein1 = {n_uniq_protein1}, n_uniq_protein2 = {n_uniq_protein2}\")\n",
        "\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHbkPH1NgjC0"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvHJsdQB4tYi"
      },
      "source": [
        "## Graded Exercises (10 points)\n",
        "\n",
        "Exercises 1 to 4 deal with the data, the graph structure, its visualization and data preparation of **FEATURES** only.\n",
        "\n",
        "Exercises 5 deals with linking the Feature data with the target data\n",
        "\n",
        "Exercise 6 deals with the classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-wokqH94zBd"
      },
      "source": [
        "### Exercise 1 (1 point): Create the networkx graph object\n",
        "\n",
        "**Hint** : Use the `networkx`'s function `add_weighted_edges_from`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI8LpqKkSbNw"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "G = nx.Graph()\n",
        "G.add_weighted_edges_from(df.values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QePwhJla5Qfs"
      },
      "source": [
        "### Exercise 2 (2 points): Network Analysis\n",
        "\n",
        "Provide the following Graph parameters\n",
        "\n",
        "1. Display the information of the network, using networks using `networkx`'s    `.info`\n",
        "2. Compute number of nodes, number of edges and the average degree of the network using  `networkx`'s   `.number_of_nodes `,   `.number_of_edges ` and `.degree` of each node and then taking its average`\n",
        "3. Density of a network  using  `networkx`'s   `.density`\n",
        "4. Compute the minimum Spanning Tree using  `networkx`'s   `.minimum_spanning_tree` and draw it using  `.spring_layout` and `.draw_networkx`\n",
        "5. Determine the Diameter and Center of the graph  using  `networkx`'s   `.diameter` and `.center`\n",
        "6. Visualise the degree distribution using a histogram    using  `networkx`'s   `.degree`\n",
        "7. List the components in a network   using  `networkx`'s   `.connected_components`\n",
        "8. Create a subrgraph   using  `networkx`'s. `.subgraph` and Print the largest Component of the network using the `max` of components\n",
        "`\n",
        "\n",
        "**Hints**: Refer to the `nx.<method>` highlighted above to achieve the respective tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCw-Xa8UQsc_"
      },
      "outputs": [],
      "source": [
        "# This is just a guideline.\n",
        "# Please use seperate cells to perfom the required tasks\n",
        "\n",
        "\n",
        "#===========================================\n",
        "# Compute number of nodes, number of edges\n",
        "# and the average degree of the network \"g\"\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# Compute the density of\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# Compute the minimum spanning tree in the\n",
        "# network \"g\" and draw it.\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# Draw the degree distribution histogram.\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# Compute largest connected component (LC)\n",
        "# of the network \"g\"\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# List the components in the network \"g\"\n",
        "#===========================================\n",
        "# YOUR CODE HERE\n",
        "\n",
        "#===========================================\n",
        "# Get the SubGraph\n",
        "#===========================================\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qnLgW7djXBi"
      },
      "source": [
        "### Exercise 3  (3 points): Centrality Feature Extraction\n",
        "\n",
        "Compute the Centralities\n",
        "\n",
        "The reason we need centralities is already established in the introduction. We are generating features for the network data to transform the network data into a Machine-learning features.\n",
        "\n",
        "For specific information, click the link adjacent to the name, or for a full list click [here](https://networkx.org/documentation/stable/reference/algorithms/centrality.html#reaching).\n",
        "\n",
        "\n",
        "In the graph/network analysis, centrality measures are vital tools for understanding the networks in detail.\n",
        "\n",
        "These algorithms use graph theory to calculate the importance of any given node in a network. They cut through noisy data, revealing parts of the network that need attention – but they all work differently. Each measure has its own definition of 'importance'. There are plenty of parameters.\n",
        "However, the following network metrics are used in the paper.\n",
        "\n",
        "\n",
        "\n",
        "1. **closeness centrality** [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.closeness_centrality.html#networkx.algorithms.centrality.closeness_centrality) {**has been provided as an example with code in the next cell**},\n",
        "2. betweenness centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html#networkx.algorithms.centrality.betweenness_centrality),\n",
        "3. degree centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html#networkx.algorithms.centrality.degree_centrality),\n",
        "4. eigenvector centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html#networkx.algorithms.centrality.eigenvector_centrality),\n",
        "5. subgraph centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.subgraph_centrality.html#networkx.algorithms.centrality.subgraph_centrality),\n",
        "8. load centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.load_centrality.html#networkx.algorithms.centrality.load_centrality),\n",
        "9. harmonic centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.harmonic_centrality.html#networkx.algorithms.centrality.harmonic_centrality),\n",
        "10. reaching (local) centrality [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.local_reaching_centrality.html#networkx.algorithms.centrality.local_reaching_centrality),\n",
        "11. pagerank [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html),\n",
        "12. clustering coefficient [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html#networkx.algorithms.cluster.clustering),\n",
        "13. average_neighbor_degree [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.assortativity.average_neighbor_degree.html)\n",
        "\n",
        "**Note**:\n",
        "\n",
        "- Most of the methods mentioned above return a dictionary ( key-value pairs of node_name: value)\n",
        "\n",
        "- Some of the methods mentioned above return only 1 number, So make sure to look into the documentation as to what it returns. In that case run the method for each node to create a dictionary of node-names and its values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzfHzhl8jWOR"
      },
      "outputs": [],
      "source": [
        "# closeness centrality\n",
        "centrality_closeness = nx.closeness_centrality(g)\n",
        "\n",
        "df_centrality_closeness = pd.DataFrame(data = np.zeros([n_uniq_protein1,2]), columns=[\"protein1\", \"centrality_closeness\"])\n",
        "df_centrality_closeness[\"protein1\"] = list(centrality_closeness.keys())\n",
        "df_centrality_closeness[\"centrality_closeness\"] = list(centrality_closeness.values())\n",
        "df_centrality_closeness = df_centrality_closeness.set_index(\"protein1\")\n",
        "df_centrality_closeness.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk6bzeYVjWLH"
      },
      "outputs": [],
      "source": [
        "# betweenness centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXHQLNnijVoP"
      },
      "outputs": [],
      "source": [
        "# degree centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2QkS94vtlJS"
      },
      "outputs": [],
      "source": [
        "# eigenvector centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlTZ106Utk57"
      },
      "outputs": [],
      "source": [
        "# subgraph centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQqxSJDdzCbS"
      },
      "outputs": [],
      "source": [
        "# information centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnrCuQgmyv2p"
      },
      "outputs": [],
      "source": [
        "# random-walk centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAj7ofeZvKn0"
      },
      "outputs": [],
      "source": [
        "# load centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEBjUB4svMXy"
      },
      "outputs": [],
      "source": [
        "# harmonic centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg4Cf3nQv5un"
      },
      "outputs": [],
      "source": [
        "# local reaching centrality\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBnSmYU-4iUj"
      },
      "outputs": [],
      "source": [
        "# pagerank\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKGS3VaV4iNf"
      },
      "outputs": [],
      "source": [
        "# clustering coefficient\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COoayE1d8toD"
      },
      "outputs": [],
      "source": [
        "# average_neighbor_degree\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F_8MS1xOIdg"
      },
      "source": [
        "### Exercise 4 (2 points): Feature Engineering and Data Preparation\n",
        "\n",
        " - Add the above computed values as new columns to the existing dataframe to form new features for machine learning.\n",
        " - Remove the columns *protein2* and the *combined_score*\n",
        " - Check for the null values. Drop if any\n",
        " - Scale the values of each column\n",
        " - Check for correlations of every feature with every other using `seaborn`'s **annotated heatmap**. Drop one of the features in the pair which exhibits a high correlation coefficient, *i.e.* $r>0.9$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5zHWM2Zv5qt"
      },
      "outputs": [],
      "source": [
        "#Add the above computed values as new columns to the existing dataframe to form new features for machine learning.\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLXSP6xFv5n4"
      },
      "outputs": [],
      "source": [
        "# Check for the null values. Drop if any\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_tIFmbO3Ld-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4ND4qyay-Up"
      },
      "outputs": [],
      "source": [
        "# Scale the features\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGcvzxu1y-SC"
      },
      "outputs": [],
      "source": [
        "# Display the correlation matrix using Heatmap\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N47ZVuly-O9"
      },
      "outputs": [],
      "source": [
        "# Drop Highly Correlating Pairs of features\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QV5rGs_Vmc3"
      },
      "source": [
        "### Excerice 5 (1 Point) : Target Data\n",
        "\n",
        "Obtain the Target Data from the file **\"Actinomyces coleocanis.csv\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK_If_pKW5jM"
      },
      "outputs": [],
      "source": [
        "df_target = pd.read_csv( \"Actinomyces_coleocanis_Essential_Genes.csv\")\n",
        "print(df_target.shape)\n",
        "df_target.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX2zLlMJW44B"
      },
      "outputs": [],
      "source": [
        "# Create a list (or a set or numpy array) of Essential Genes from the above DataFrame\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__ZMLWZoo576"
      },
      "outputs": [],
      "source": [
        "# Create a new feature called \"gene_essentiality\"\n",
        "# Assign 1 to the protein1 if it is present in the list of essential genes\n",
        "# This becomes your target variable\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0vSkAhPUU6"
      },
      "source": [
        "### Exercise 6 (1 point) : Gene Essentiality Classification\n",
        "\n",
        "Determine the Essential Protein using any of your favourite `sklearn`'s classifier models\n",
        "\n",
        "- Split the data into training and testing datasets\n",
        "- Build a model, fit and predict\n",
        "- Print the classification report, Confusion Matrix and ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NkSkLtvqFCU"
      },
      "outputs": [],
      "source": [
        "# Train-test split the features and target\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q80_h-WLrYw4"
      },
      "outputs": [],
      "source": [
        "# Instantiate a model (Classifier)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Fit on Train data\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Predict on test data\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMuFooE5qE3C"
      },
      "outputs": [],
      "source": [
        "# Print the confusion Matrix\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Print the classification Report\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Plot the ROC Curve\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvlu1mhhyVoc"
      },
      "source": [
        "#### Discuss your findings and the learning that happened with this mini-project to your Mentor."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}