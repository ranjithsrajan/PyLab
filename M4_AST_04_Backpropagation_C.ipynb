{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjithsrajan/PyLab/blob/main/M4_AST_04_Backpropagation_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powered-thong"
      },
      "source": [
        "# Applied Data Science and Machine Intelligence\n",
        "## A program by IITM and TalentSprint\n",
        "### Assignment 03 : Back Propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9M4Ca7dCDL"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr5QnG2PdCDP"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* Understanding how back propagation happens in Computational Graphs\n",
        "* understanding back propagation algoirthm in Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVc_4Z46sgGF"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzEiPeZnsgGH"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95W_th8VsgGI"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "toJ3sOFqqUQ4"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M4_AST_04_Backpropagation_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword(),\"batch\":\"IITM-PG-ADSML-07\"}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support,\"batch\":\"IITM-PG-ADSML-07\"}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iitm.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4a. Back Propagation in Computational Graphs"
      ],
      "metadata": {
        "id": "HOC-0ztq9QdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries"
      ],
      "metadata": {
        "id": "Xa54EbrG5Fkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "HgE67rMI5TRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computational Graphs"
      ],
      "metadata": {
        "id": "3u6LcoW-tPT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A computational graph is defined as a directed graph where the nodes correspond to mathematical operations. Computational graphs are a way of expressing and evaluating a mathematical expression.\n",
        "\n",
        "#### Forward Pass\n",
        "Forward pass is the procedure for evaluating the value of the mathematical expression represented by computational graphs. Doing forward pass means we are passing the value from variables in forward direction from the inputs to output."
      ],
      "metadata": {
        "id": "sNGCStJotN3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 2   #x,y and z are inputs to the graph\n",
        "y = 4\n",
        "z = 0.5\n",
        "w = 2\n",
        "\n",
        "u = x + y\n",
        "v = z * w\n",
        "\n",
        "\n",
        "b = u * v  # b is the output\n",
        "print(b)"
      ],
      "metadata": {
        "id": "HLs3x7f7oNXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Back Propagation in Computational graphs\n",
        "\n",
        "\n",
        "Backpropagation is useful for knowing how nodes that aren’t directly connected affect each other?\n",
        "\n",
        " Let’s consider how b is affected by x i.e. ∂b/∂x . If we change x at a speed of 1, u changes at a speed of 1. In turn, changing u, causes b to change at a speed of v. So b changes at a rate of v with respect to x.\n",
        "\n",
        "The general rule is to sum over all possible paths from one node to the other, multiplying the derivatives on each edge of the path together."
      ],
      "metadata": {
        "id": "MQ6H9o2Hsibf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As \\$b = u * v $\n",
        "\n",
        "$Using\\ multiplication \\ rule\\ of\\ differentiation$\n",
        "\\begin{equation*} \\frac{∂b} {∂u} = u * \\frac{∂v} {∂u} + v * \\frac{∂u} {∂u} \\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂u} = u * 0 + v * 1 \\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂u} =  v \\end{equation*}\n",
        "\n",
        "$Similarly$ \\begin{equation*} \\frac{∂b} {∂v} = u \\end{equation*}\n",
        "\n",
        "$Now $\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂x} =  \\frac{∂b} {∂u} * \\frac{∂u} {∂x} + \\frac{∂b} {∂v} * \\frac{∂v} {∂x} \\end{equation*}\n",
        "\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂x} =  v * 1 + u * 0 = v \\end{equation*}\n",
        "\n",
        "\n",
        "$Similarly $\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂y} =  \\frac{∂b} {∂u} * \\frac{∂u} {∂y} + \\frac{∂b} {∂v} * \\frac{∂v} {∂y} = v * 1  + u * 0  \\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂z} =  \\frac{∂b} {∂u} * \\frac{∂u} {∂z} + \\frac{∂b} {∂v} * \\frac{∂v} {∂z} = v * 0  + u * w  \\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂w} =  \\frac{∂b} {∂u} * \\frac{∂u} {∂w} + \\frac{∂b} {∂v} * \\frac{∂v} {∂w} = v * 0  + u * z  \\end{equation*}\n",
        "\n",
        "\n",
        "$Given\\ x = 2, y = 4, z = 0.5\\ and\\ w = 2 $\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂x} =  v =  z*w = 1\\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂y} =  v = 1\\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂z} =  u*w =  12\\end{equation*}\n",
        "\n",
        "\\begin{equation*} \\frac{∂b} {∂w} =  u*z =  3\\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V8PwysP9mROZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4b. Back Propagation in Neural Networks"
      ],
      "metadata": {
        "id": "28PpQ-E49Z_T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJt-uGJvymM2"
      },
      "source": [
        "### Problem Statement: Implementing the Iris data using Backpropagation in Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTMfvxuSrLUR"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz2T6C2MrPp6"
      },
      "source": [
        "#### History\n",
        "\n",
        "This is a multivariate dataset introduced by R.A.Fisher (Father of Modern Statistics) for showcasing linear discriminant analysis. This is arguably the best known dataset in Feature Selection literature.\n",
        "\n",
        "\n",
        "The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62AAQoRKrQIK"
      },
      "source": [
        "#### Description\n",
        "The Iris dataset consists of 150 data instances. There are 3 classes (Iris Versicolor, Iris Setosa and Iris Virginica) each have 50 instances.\n",
        "\n",
        "\n",
        "For each flower we have the below data attributes\n",
        "\n",
        "- sepal length in cm\n",
        "- sepal width in cm\n",
        "- petal length in cm\n",
        "- petal width in cm\n",
        "\n",
        "To make our experiment easy we rename the classes  with numbers :\n",
        "\n",
        "    \"0\": setosa\n",
        "    \"1\": versicolor\n",
        "    \"2\": virginica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-KMXJrArUFg"
      },
      "source": [
        "### Challenges\n",
        "\n",
        "When we use the data with large number of features or dimensionality, models usually choke because\n",
        "\n",
        "    1. Training time increases exponentially with number of features.\n",
        "    2. Models have increasing risk of overfitting with increasing number of features.\n",
        "    \n",
        "To avoid the above mentioned problems while learning about data analysis, we use simple, well behaved, data that reduces the cognitive load, and makes it easier to debug as we are able to better comprehend the data we are working with.  \n",
        "\n",
        "Hence, this is a good dataset to work on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lEbv7grYmm"
      },
      "source": [
        "## Domain Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIB3dtlNrWy6"
      },
      "source": [
        "\n",
        "\n",
        "Iris Plants are flowering plants with showy flowers. They are very popular among movie directors as it gives excellent background.\n",
        "\n",
        "They are predominantly found in dry, semi-desert, or colder rocky mountainous areas in Europe and Asia. They have long, erect flowering stems and can produce white, yellow, orange, pink, purple, lavender, blue or brown colored flowers. There are 260 to 300 types of iris.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1275/1*7bnLKsChXq94QjtAiRn40w.png)\n",
        "\n",
        "As you could see, flowers have 3 sepals and 3 petals.  The sepals are usually spreading or drop downwards and the petals stand upright, partly behind the sepal bases. However, the length and width of the sepals and petals vary for each type.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries"
      ],
      "metadata": {
        "id": "3_7hNGrE2y_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "5NIn9gzF2y_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPLLaOx_aVO6"
      },
      "source": [
        "#### Define the inputs and structure of the neural networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Get features and target\n",
        "X=data.data\n",
        "y=data.target"
      ],
      "metadata": {
        "id": "NsngLg1Y4Cgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The data matrix:\\n',data['data'])\n",
        "print('The classification target:\\n',data['target'])"
      ],
      "metadata": {
        "id": "qxkV4V-OoXf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dummy variable\n",
        "y = pd.get_dummies(y).values\n",
        "\n",
        "y[46:56]"
      ],
      "metadata": {
        "id": "9Tnq4mzk_Ves"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
      ],
      "metadata": {
        "id": "WuOYx_cl7o-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "learning_rate = 0.4\n",
        "iterations = 5000\n",
        "N = y_train.size\n",
        "\n",
        "# number of input features\n",
        "input_size = 4\n",
        "\n",
        "# number of hidden layers neurons\n",
        "hidden_size = 2\n",
        "\n",
        "# number of neurons at the output layer\n",
        "output_size = 3\n",
        "\n",
        "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
      ],
      "metadata": {
        "id": "sN6annZe7uZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "np.random.seed(10)\n",
        "\n",
        "# initializing weight for the hidden layer\n",
        "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))\n",
        "\n",
        "# initializing weight for the output layer\n",
        "W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size))"
      ],
      "metadata": {
        "id": "i8QSSWCf7w2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B-hoQtcvuac"
      },
      "source": [
        "#### Update the weights using feedforward and backpropagation algorithm\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com//DLFA/Experiment_related_data/XOR.png\" width=700px/>\n",
        "</center>\n",
        "\n",
        "For simplicity we consider '$W_{11}$', '$W_{12}$', '$W_{21}$' and '$W_{22}$' as weight vector '$W_{1}$'. Weights '$W_{3}$' and '$W_{4}$' as '$W_{2}$'\n",
        "\n",
        "Here 'Z' is the dot product of weight vector 'W' and the input vector 'X'. Again we vectorize '$Z_{11}$', '$Z_{12}$' as '$Z_{1}$' and '$Z_{2}$' remains same\n",
        "\n",
        "$'A'$ is the activation function. We used sigmoid activation function in our network. Vectorizing $'A_{11}'$ and $'A_{12}'$ gives $'A_{1}'$ and $'A_{2}'$ is kept the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik9tBgpXKmGK"
      },
      "source": [
        "#### Forward propagation\n",
        "\n",
        "In the forward propagation all 'Z' and 'A' will be calculated until we get to the end of our network giving us our prediction 'Y'.\n",
        "\n",
        "$ Z_{1} = W_1 . X + b_1$     --------> 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV60omIIKfQ5"
      },
      "source": [
        "#### Activation Function\n",
        "\n",
        "Sigmoid function is a S-shaped curve which predicts the probability as an ouput.\n",
        "\n",
        "$A_1 = \\frac{1}{1 + e ^ {- Z_1}}$   ---------> 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv9dDvkKLuFa"
      },
      "source": [
        "$ Z_{2} = W_2 . A_1 + b_2$    ---------> 3\n",
        "\n",
        "Y = $A_2 = \\frac{1}{1 + e ^ {- Z_2}}$   ---------> 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwXEuxUTbNe9"
      },
      "source": [
        "# Sigmoid Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def mean_squared_error(y_pred, y_true):\n",
        "    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)"
      ],
      "metadata": {
        "id": "68Obd-TU_iVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t3jbYr-GtEO"
      },
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
        "    return acc.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = np.array([0.6,0.2,-0.1]).argmax()\n",
        "a1 = np.array([1,0,0]).argmax()"
      ],
      "metadata": {
        "id": "T7FdOLQ5bFMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1==a1"
      ],
      "metadata": {
        "id": "AVl-cbkfbTX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLO4uCjAyEXd"
      },
      "source": [
        "Basic Algorithm which explains feedforward and backpropagation\n",
        "\n",
        "1. Inputs are taken\n",
        "2. The weights are usually randomly selected.\n",
        "3. Calculate the output of every neuron from the input layer, to the hidden layers and to the output layer.\n",
        "4. Apply sigmoid function at hidden and output layers.\n",
        "5. Calculate the error in the outputs\n",
        "\n",
        "    *Error = Predicted Output – Actual Output*\n",
        "5. Travel back from the output layer to the hidden layer to adjust the weights such that the error is minimized.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woRC6ENkhkQo"
      },
      "source": [
        "**Chain rule to find the change in error with respect to W2 (Weights):**\n",
        "\n",
        "$\\frac{\\partial E}{\\partial W_{2}} = \\frac{\\partial E}{\\partial O} \\cdot \\frac{\\partial O}{\\partial Z_{2}} \\cdot \\frac{\\partial Z_{2}}{\\partial W_{2}}$\n",
        "\n",
        "* **Change in error with respect to output**\n",
        "\n",
        "  Suppose the actual output is represented as 'O' and the predicted output is represented as 'a2', then the error would be calculated as:\n",
        "\n",
        "  $E = \\frac{1}{2}\\left ( a2-O \\right )^{2}$\n",
        "\n",
        "  Differentiate the error with respect to the output\n",
        "\n",
        "  $\\frac{\\partial E}{\\partial O} = -\\left (a2-O  \\right )$\n",
        "\n",
        "   $\\frac{\\partial E}{\\partial O} = O-a2$\n",
        "\n",
        "  In the code, `predicted output` is represented as `output_layer_outputs` and the `actual output` is represented as y\n",
        "\n",
        "* **Change in output with respect to Z2**\n",
        "\n",
        "  Thus, $\\frac{\\partial O}{\\partial Z_{2}}$ is effectively the derivative of Sigmoid\n",
        "\n",
        "  $f\\left ( z \\right ) = \\frac{1}{1+e^{-z}}$\n",
        "\n",
        "  $f'(z) = (1+e^{-z})-1[1-(1+e^{-z})-1]$\n",
        "\n",
        "  ${f}'\\left ( z \\right ) = sigmoid(z)(1-sigmoid(z))$\n",
        "\n",
        "  $\\frac{\\partial O}{\\partial Z_{2}} = (a2)(1-a2)$\n",
        "\n",
        "\n",
        "* **Change in $Z_2$ with respect to $W_2$ (Weights)**\n",
        "\n",
        "  $Z_2 = W^T.A_1 $\n",
        "\n",
        "  On differentiating $Z_2$ with respect to $W_2$, we will get the value $A_1$ itself\n",
        "\n",
        "  $\\frac{\\partial Z_{2}}{\\partial W_{2} }$ = $A_1$ where $A_1$ = $sigmoid(Z_{1})$\n",
        "\n",
        "**Chain rule to find the change in error with respect to W2 (Weights):**\n",
        "\n",
        "$\\frac{\\partial E}{\\partial W_{2}} = \\frac{\\partial E}{\\partial O} \\cdot \\frac{\\partial O}{\\partial Z_{2}} \\cdot \\frac{\\partial Z_{2}}{\\partial W_{2}}$\n",
        "\n",
        "$\\frac{\\partial E}{\\partial W_{2}} = (a2-y) . a2(1-a2). A_1$\n",
        "\n",
        "In the code $A_1$ is represented as $a_1$\n",
        "\n",
        "**Update the weights using Gradient Descent**\n",
        "\n",
        "$W_{new} = W_{old} - lr * \\frac{\\partial E}{\\partial W_{2}} $\n",
        "\n",
        "In the code, $W_{old}$ is represented as $w_2$,  $lr$ is represented as learning rate and $\\frac{\\partial E}{\\partial W}$ is represented as $W_2$.\n",
        "\n",
        "Similarly, W1 (Weights) are updated using chain rule.\n",
        "\n",
        "**Note:** For more details refer to the following [link](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp_df = pd.DataFrame({\"mse\": [mse], \"accuracy\": [acc]})  # Create a temporary DataFrame\n",
        "# results = pd.concat([results, temp_df], ignore_index=True)  # Concatenate with existing results"
      ],
      "metadata": {
        "id": "ixYAncJKbPwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(iterations):\n",
        "\n",
        "    # feedforward propagation\n",
        "    # on hidden layer\n",
        "    Z1 = np.dot(X_train, W1)\n",
        "    A1 = sigmoid(Z1)\n",
        "\n",
        "    # on output layer\n",
        "    Z2 = np.dot(A1, W2)\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "\n",
        "    # Calculating error\n",
        "    mse = mean_squared_error(A2, y_train)\n",
        "    acc = accuracy(A2, y_train)\n",
        "    print(f\" MSE : {mse},acc : {acc}\")\n",
        "\n",
        "    temp_df = pd.DataFrame({\"mse\": [mse], \"accuracy\": [acc]})  # Create a temporary DataFrame\n",
        "    results = pd.concat([results, temp_df], ignore_index=True)  # Concatenate with existing results\n",
        "\n",
        "    # backpropagation\n",
        "    E1 = A2 - y_train\n",
        "    dW1 = E1 * A2 * (1 - A2)\n",
        "    W2_update = np.dot(A1.T, dW1) / N\n",
        "\n",
        "    E2 = np.dot(dW1, W2.T)\n",
        "    dW2 = E2 * A1 * (1 - A1)\n",
        "    W1_update = np.dot(X_train.T, dW2) / N\n",
        "\n",
        "\n",
        "\n",
        "    W2 = W2 - learning_rate * W2_update\n",
        "    W1 = W1 - learning_rate * W1_update"
      ],
      "metadata": {
        "id": "8mUgjaIg74Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.mse.plot(title=\"Mean Squared Error\")"
      ],
      "metadata": {
        "id": "XASfnMNR7-P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.accuracy.plot(title=\"Accuracy\")"
      ],
      "metadata": {
        "id": "KseIl9KW8BM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feedforward\n",
        "Z1 = np.dot(X_test, W1)\n",
        "A1 = sigmoid(Z1)\n",
        "\n",
        "Z2 = np.dot(A1, W2)\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "acc = accuracy(A2, y_test)\n",
        "print(\"Accuracy: {}\".format(acc))"
      ],
      "metadata": {
        "id": "uZdKZz1L8E1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zlW2FdY5_JK"
      },
      "source": [
        "Our goal with backpropagation is to update each of the weights in the network so that predicted output will be closer to the actual output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIXvVFHfNHSC"
      },
      "source": [
        "# Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBssUAioZvhE"
      },
      "outputs": [],
      "source": [
        "# @title Suppose the network has 784 inputs, 32 neurons in the first hidden layer, 16 neurons in the second hidden layer, and 10 neurons in the output layer. How many parameters (weights) does the network have?   { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"25248\", \"25600\",\"672\",\"25760\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo6-cFjksrUq"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzugcZdhsrUr"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y-TKNRWsrUs"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ole8PFYTsrUt"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYXU9Ek_srUu"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BDUydro1srUv"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ]
}